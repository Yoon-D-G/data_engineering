{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON, CSV, XLSX, and YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working in projects involved in AI, most likely you will need to deal with files with different formats. Some of the most common formats are JSON, CSV, XLSX, and YAML.\n",
    "\n",
    "In this notebook, we are making a brief introduction to each one of them, as well as giving some comments on how and when to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work with some files with the data formats we mentioned, so before start reading the notebook, make sure to run the following cell to download the necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/Salaries.csv\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/employees.xml\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/demo.xlsx\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/JSON_sample.json\" \"https://aicore-files.s3.amazonaws.com/Foundations/Data_Formats/yaml_example.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1> CSV __(comma-separated values)__ files are a very common way to store data. </font>\n",
    "\n",
    "- Their most common literal representation is a bunch of values, separated by commas, as the name would indicate.\n",
    "- All of the data for a single observation is on one line: each new line is a new observation.\n",
    "- The comma in this case is called the __'delimiter'__ as it shows the difference (or limit) between one value and the next.\n",
    "- Other common delimiters are semi-colons and tabs (also called __tsv/tab-separated values__).\n",
    "- We must be careful to check what exactly the delimiter is, as a common error is reading in a file with the wrong delimiter, and so getting a weird representation in your data.\n",
    "- CSVs can also be read by Excel.\n",
    "<p style=\"font-size:10.5px\">\n",
    "Usually if you are using data from mainland European countries (France/Spain etc) they will use semi-colons, hence some people prefer <i>character</i>-separated values for CSV.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python counts with a library called `csv` that has the needed functionalities to read and write CSV files.\n",
    "\n",
    "We open an existing file (Salaries.csv) using a context manager, and the mode in the context manager is set to read (`r`). Then, use the reader class from csv, which will take the values in the csv and store them into a variable that becomes an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Salaries.csv', mode='r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for n, row in enumerate(reader):\n",
    "        print(','.join(row))\n",
    "        if n == 5: # Read only the first five entrances\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same library can be used to generate csv files. The only thing you need to change is the mode argument in the context manager is write (`w`). If you want to append things to the csv, you can use the mode append (`a`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As opposed to reading a CSV file, if we write a CSV, we need to use the `writer` class, which will point to the file we want to create. Notice that the file we want to generate doesn't necessarily have to exist (if it exists, it will overwrite its content)\n",
    "\n",
    "The `writer` object has some methods to create a new file. The most common one is `writerows`, which accepts iterables as arguments, and parse them into a comma separated row\n",
    "\n",
    "So, if we define a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [['Sparky', 7, 'Brown', 'Corgi'], ['Fido', 4, 'White', 'Husky']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new csv file where each row contains the characteristic of each dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Dogs.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Name', 'Age', 'Colour', 'Breed'])\n",
    "    writer.writerows(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the difference between `writerow` and `writerows`. Try running the following cell and see if you see any difference between both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Dogs_2.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Name', 'Age', 'Colour', 'Breed'])\n",
    "    writer.writerow(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=+1> JSON (JavaScript Object Notation) is a file format that stores data in a way that is easily readable by both humans and machines.</font>\n",
    "\n",
    "- It is as useful way for a browser and a server to exchange data, so it is used extensively in Web-based applications of coding.\n",
    "- In fact, Jupyter Notebook .ipynb files are actually stored in JSON format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON format is very similar to Python dictionaries, they contain a key and it has a corresponding value to that key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers a library called `json` that can read, write, or append elements from or to a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is very similar to the one for CSV files. We use a context manager, set the mode we want to use, and then use a method. In this case, for reading a file, we use the `load` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('JSON_sample.json', mode='r') as f:\n",
    "    json_dict = json.load(f)\n",
    "\n",
    "print(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that, whatever we read, is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create json files from dictionaries. Observe that the mode of the context manager is `w`. The method in this case is `dump`. The `dump` method accepts the data we want to use, and then the file we want to dump the data into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "with open('JSON_test.json', mode='w') as f:\n",
    "    json.dump(test_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe in your directory that now you have a `json` file called `JSON_test.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a string containing a json and parse it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = json.loads(x)\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful with the double quotes! If your keys have single quotes, the json parser will not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  \"{'name': 'John', 'age': 30, 'city': 'New York'}\"\n",
    "y = json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the opposite (from dictionary to JSON string) using the `dumps` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = {'a': 3, 'b': 4}\n",
    "new_json = json.dumps(test_dict)\n",
    "print(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XLSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XLSX is the de facto Excel format. As you might know, an Excel file is a workbook that can contain many sheets inside, so we need to define the sheet we want to work with. There are many libraries that allow us to read xlsx files. One of the most famous is openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read XLSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we don't need a context manager to read a XLSX file. We can simply use the `load_workbook` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case openpyxl is not installed, run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "workbook = openpyxl.load_workbook('demo.xlsx')\n",
    "sheet = workbook.active\n",
    "print(sheet) # This will print the name of the active worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel worksheets are divided into cells, so we can access the values of each cell indexing the cell we want to get information about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet['B2'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the values of many cells using slicing, which will return a tuple of the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_range = sheet['A1':'C13']\n",
    "print(cell_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can iterate through it, and use the value attribute to read the content of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cell_range:\n",
    "    print(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But observe that we have a range with three columns. We might need to use a nested loop, so one loop iterates trhough the rows, and the ineer loop iterates through the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in cell_range:\n",
    "    for row in column:\n",
    "        print(row.value, end=' ') # Use the end parameter for not adding a new line after printing an element\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get information about the number of rows and columns we have in the worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sheet.max_row)\n",
    "print(sheet.max_column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access a different sheet from the same workbook, you can simply index the name of the sheet. First, we might want to take a look at the available worksheets we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.sheetnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, so let's work with the \"Instructors\" spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_instructors = workbook['Instructors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_range = ws_instructors['A1':'C5']\n",
    "for column in cell_range:\n",
    "    for row in column:\n",
    "        print(row.value, end=' ') # Use the end parameter for not adding a new line after printing an element\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create XLSX files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create an xlsx file from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an new Excel file and add a worksheet.\n",
    "workbook = openpyxl.Workbook()\n",
    "\n",
    "# A workbook is always created with at least one worksheet. You can get it by using the Workbook.active property\n",
    "worksheet = workbook.active # \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the name of the first worksheet is 'Sheet'. You can change the name of the spreadsheet using the title argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet.title = 'New_Spreadsheet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add worksheets using the Workbook.create_sheet() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet_1 = workbook.create_sheet('First_Sheet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to save the progress, you can use the `save` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.save('XLSX_file.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have created a new file called `XLSX_file.xlsx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data in the workbook is quite straightforward. Simply assign a value to each cell by indexing the cell we want to write data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = openpyxl.Workbook()\n",
    "worksheet = workbook.active\n",
    "\n",
    "worksheet['A1'] = 'First Column, First Row'\n",
    "worksheet['B1'] = 'Second Column, First Row'\n",
    "worksheet['C4'] = 'Hello there'\n",
    "\n",
    "workbook.save('XLSX_file_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YAML is a data serialization language, which means that it is a common language across different applications. In fact, you already saw a serialization language in this lesson: JSON.\n",
    "\n",
    "> <font size=+1> YAML (YAML Ain't Markup Language) is a data serialization language </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage of YAML is that is highly human-readable. You can see a comparison between JSON and YAML containing the same information.\n",
    "### YAML:\n",
    "```\n",
    "simple-property: a simple value\n",
    "\n",
    "object-property:\n",
    "    first-property: first value\n",
    "    second-property: second value\n",
    "\n",
    "array-property:\n",
    "    - item-1-property-1: one\n",
    "      item-1-property-2: 2\n",
    "    - item-2-property-1: three\n",
    "      item-2-property-2: 4\n",
    "```\n",
    "\n",
    "### JSON\n",
    "```\n",
    "{\n",
    "  \"simple-property\": \"a simple value\",\n",
    "\n",
    "  \"object-property\": {\n",
    "      \"first-property\": \"first value\",\n",
    "      \"second-property\": \"second value\",\n",
    "  },\n",
    "\n",
    "  \"array-property\": [\n",
    "      { \"item-1-property-1\": \"one\",\n",
    "        \"item-1-property-2\": 2 },\n",
    "      { \"item-2-property-1\": \"three\",\n",
    "        \"item-2-property-2\": 4}\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the base of YAML files lies in the indentation and the linespaces.\n",
    "\n",
    "The most basic syntax in a YAML file is the __key:value__ pair\n",
    "```\n",
    "key: value\n",
    "```\n",
    "For example:\n",
    "```\n",
    "# This is a comment\n",
    "name: Ivan\n",
    "surname: 'Ying'\n",
    "role: \"Instructor\"\n",
    "IQ: 0\n",
    "```\n",
    "Notice that strings can be either into double quotes, single quotes or nothing, and they will work the same.\n",
    "\n",
    "Another useful way of using YAML files is leveraging __objects__ simply by indenting the key:value pairs:\n",
    "```\n",
    "# This is a comment\n",
    "Person:\n",
    "    name: Ivan\n",
    "    surname: 'Ying'\n",
    "    role: \"Instructor\"\n",
    "    IQ: 0\n",
    "```\n",
    "Same as with Python, indentation should be at the right level, and it would be a good idea to have a linter for checking it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look for `docs-yaml` in your Extensions tab on VSCode to install a linter to tell you whether your YAML file is well indented or not. Or you can also visit [this link](https://codebeautify.org/yaml-validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing you can use in YAML files are lists. List can contain single values, or it can also contain key:value pair values\n",
    "```\n",
    "Person:\n",
    "    - name: Ivan\n",
    "      surname: 'Ying'\n",
    "      role: \"Instructor\"\n",
    "      IQ: 0\n",
    "    - name: Not Ivan\n",
    "      surname: 'Gniy'\n",
    "      role: \"Doppelganger\"\n",
    "      IQ: 150\n",
    "Animals:\n",
    "    - Cat\n",
    "    - Dog\n",
    "    - Shoebill\n",
    "    - Kakapo\n",
    "```\n",
    "The last list can also be written as:\n",
    "```\n",
    "Animals: [Cat, Dog, Shoebill, Kakapo]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read YAML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python doesn't have a library for reading YAML files. But not to worry, you can install a library that allows you to do so. The library is named `PyYAML`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyYAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, some libraries don't have the same name as they are published with. In this case, if you want to use the PyYAML library, you simply need to import `yaml`\n",
    "\n",
    "Like CSVs and JSONs, we might want to use a context manager with the read mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('yaml_example.yaml', 'r') as stream:\n",
    "    data_loaded = yaml.safe_load(stream)\n",
    "\n",
    "print(type(data_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that, same as with JSON files, we obtain a dictionary. Let's print it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loaded)\n",
    "print(data_loaded.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have two main keys, 'Person', and 'Animal'. The value corresponding to 'Person' is a list with dictionaries, and the value corresponding to 'Animal' is just a regular list\n",
    "\n",
    "So we can get the values of it by indexing the correct key and/or index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The first element of Person is: {data_loaded['Person'][0]}\")\n",
    "print(f\"The name of the first element of Person is: {data_loaded['Person'][0]['name']}\")\n",
    "print(f\"The second element of Person is: {data_loaded['Person'][1]}\")\n",
    "print(f\"The name of the second element of Person is: {data_loaded['Person'][1]['name']}\")\n",
    "print(f'The value corresponding to Animals is: {data_loaded[\"Animals\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create YAML files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create YAML using the same library. The variable you need to use to create a YAML file is a dictionary. So, let's define a simple dictionary out of a JSON file we have, and then create a YAML from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('JSON_sample.json', mode='r') as f:\n",
    "    my_dict = json.load(f)\n",
    "\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `dump` method to save the dictionary as a yaml file. The `dump` method accepts the data we want to use, and then the file in which we want to dump our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YAML_from_JSON.yaml', 'w') as f:\n",
    "        yaml.dump(my_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows us to read these data formats in an easy way, so we don't have to think about the libraries or modules that we need to import\n",
    "\n",
    "The syntax is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_{format}('FILE_DIR')\n",
    "\n",
    "df.to_{format}('FILE_DIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and CSV\n",
    "The syntax for reading in a CSV to pandas is thus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save the read_csv to a variable\n",
    "df = pd.read_csv('<filename>')\n",
    "\n",
    "# the to_csv method is a method off a data frame\n",
    "df.to_csv('<filename>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read in the csv file\n",
    "df = pd.read_csv('Salaries.csv', index_col='Id')\n",
    "\n",
    "# show as DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get only the first 5 rows and save that into a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short = df.head(5)\n",
    "df_short\n",
    "df_short.to_csv('Salaries_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pandas can also read and write from and to JSON using the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json\n",
    "df = pd.read_json('JSON_sample.json')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look good... We have to normalize each value in that column, so each key corresponds to a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employees']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nice = pd.json_normalize(df[\"Employees\"])\n",
    "df_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nice.to_json('JSON_sample_new.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and XLSX\n",
    "- pandas cannot read in formulas, macros or graphs, only raw data.\n",
    "- Also, we must specify the sheetname to read in as a data frame or write to when using the read_excel and to_excel methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_excel has the same file stipulations as all read_ methods\n",
    "df = pd.read_excel('<filename>',sheet_name='<sheetname>')\n",
    "\n",
    "# remember to specify sheet name with Excel files\n",
    "df.to_excel('<filename>',sheet_name='<sheetname>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will rely on a file we created earlier in the XLSX section\n",
    "\n",
    "df = pd.read_excel('XLSX_file_2.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the empty values are transformed into NaN values.\n",
    "\n",
    "There is something wrong with this... It is taking the first row of the Excel file as the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('XLSX_file_2.xlsx', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better... But now it just give some numeric values to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('XLSX_file_2.xlsx', header=None, names=['First_Column', 'Second_Column', 'Third Column'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the sheet we want to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('demo.xlsx', sheet_name='Instructors')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('demo.xlsx', sheet_name='Students')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can give numeric values if we know their relative position in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('demo.xlsx', sheet_name=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load all of them, but this will return a dictionaries, where each value correspond to each dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('demo.xlsx', sheet_name=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Students']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas and YAML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas doesn't have a direct method to read a YAML file. You will have to go through the next lesson to figure out how to do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We now understand the basic file formats of CSV, XLSX, JSON, and YAML\n",
    "- We now know how to read them into pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference only: XML\n",
    "- XML (eXtensible Markup Language) is another way of exchanging data between browsers and servers (JSON is an alternative to XML).\n",
    "- Hence, like with JSON, we can use XML to obtain data from the web and they have the extension `.xml`.\n",
    "- XML is a markup language like HTML, so it contains data, and information on how to structure that data, but not how it is displayed.\n",
    "- Hence we need an API to extract data from an XML file.\n",
    "- You can use the following process although it is not the only possible way to do it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML Structure\n",
    "\n",
    "XML Documents are structured much like HTML:\n",
    "- They are hierarchical in structure.\n",
    "- The document usually contains a prolog tag containing meta data, such as version, character encoding and associated style sheet.\n",
    "- The next tag will be the root(`data` in this case) tag which will contain all other tags of the document.\n",
    "- Each tag is completely flexible in it's naming unlike HTML which has a pre-defined set of tags.\n",
    "\n",
    "#### Components of XML\n",
    "\n",
    "- __Document:__ The root tag opens the document in this case `<data>` and the ending tag `</data>` closes it.\n",
    "- __Node:__ Each tag containing other tags is a node tag here `<employee>` is a node tag.\n",
    "- __Elements:__ Elements such as `<email>alpha@aicore.com</email>` and ` <age>36</age>` are considered elements.\n",
    "- __Content:__ The data between the elements tags are considered content. In the email element `<email>alpha@aicore.com</email>`, the string `alpha@aicore.com` is considered the content.\n",
    "\n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<data>\n",
    "    <employee name=\"Alpha\">\n",
    "        <email>alpha@aicore.com</email>\n",
    "        <department>HR</department>\n",
    "        <age>36</age>\n",
    "    </employee>\n",
    "    <employee name=\"Bravo\">\n",
    "        <email>bravo@aicore.com</email>\n",
    "        <department>sales</department>\n",
    "        <age>23</age>\n",
    "    </employee>\n",
    "    <employee name=\"Charlie\">\n",
    "        <email>charlie@aicore.com</email>\n",
    "        <department>accounts</department>\n",
    "        <age>44</age>\n",
    "    </employee>\n",
    "    <employee name=\"Delta\">\n",
    "        <email>delta@aicore.com</email>\n",
    "        <department>reception</department>\n",
    "        <age>51</age>\n",
    "    </employee>\n",
    "</data>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can use this premade function to parse in XML files, which requires only 2 arguments:\n",
    "    - The XML filename\n",
    "    - The columns of the data frame (the fields in each observation in the XML file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "def parse_XML(xml_file, df_cols): \n",
    "    \"\"\"Parse the input XML file and store the result in a pandas \n",
    "    DataFrame with the given columns. \n",
    "    \n",
    "    The first element of df_cols is supposed to be the identifier \n",
    "    variable, which is an attribute of each node element in the \n",
    "    XML data; other features will be parsed from the text content \n",
    "    of each sub-element. \n",
    "    \"\"\"\n",
    "    \n",
    "    xtree = et.parse(xml_file)\n",
    "    xroot = xtree.getroot()\n",
    "    rows = []\n",
    "    \n",
    "    for node in xroot: \n",
    "        res = []\n",
    "        res.append(node.attrib.get(df_cols[0]))\n",
    "        for el in df_cols[1:]: \n",
    "            if node is not None and node.find(el) is not None:\n",
    "                res.append(node.find(el).text)\n",
    "            else: \n",
    "                res.append(None)\n",
    "        rows.append({df_cols[i]: res[i] \n",
    "                     for i, _ in enumerate(df_cols)})\n",
    "    \n",
    "    out_df = pd.DataFrame(rows, columns=df_cols)\n",
    "        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_XML(\"employees.xml\", [\"name\", \"email\", \"department\", \"age\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read `.xml` files using pandas `read_xml` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameter `attrs_only` we can specify only showing the tags with attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\", attrs_only=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `elems_only` parameter we can specify only showing the data from element tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_xml(\"employee.xml\", elems_only=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert the dataframe easily back to an XML document with the `to_xml` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_xml(\"employees_df_export\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
